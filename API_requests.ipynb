{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "API requests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODKbRK4TFdW3x601f3zJ3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHRISTINEMUTHEE/API_REQUEST/blob/main/API_requests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requesting data from an API.\n",
        "### API's allow us to make requests from servers to retrieve data"
      ],
      "metadata": {
        "id": "dQq2Yu2X2oeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0OEj3J0qciA",
        "outputId": "c496095b-1136-4342-c621-e4dc44c9cc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "# Installing the requests package \n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Library \n",
        "import requests\n",
        "url=\"https://dog.ceo/api/breeds/list/all\"\n",
        "response= requests.get(url)\n",
        "print(response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVC3qqVYqrtf",
        "outputId": "eea24278-89e6-4119-c955-4ae1f67891c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting data from a specific dictionary key\n",
        "specific_species=response.json()['message']"
      ],
      "metadata": {
        "id": "kY4G90f9vPtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(specific_species)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uskzs5xfOd",
        "outputId": "e4b3e532-a0f8-43b3-f8ef-4e5b02193f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'affenpinscher': [], 'african': [], 'airedale': [], 'akita': [], 'appenzeller': [], 'australian': ['shepherd'], 'basenji': [], 'beagle': [], 'bluetick': [], 'borzoi': [], 'bouvier': [], 'boxer': [], 'brabancon': [], 'briard': [], 'buhund': ['norwegian'], 'bulldog': ['boston', 'english', 'french'], 'bullterrier': ['staffordshire'], 'cattledog': ['australian'], 'chihuahua': [], 'chow': [], 'clumber': [], 'cockapoo': [], 'collie': ['border'], 'coonhound': [], 'corgi': ['cardigan'], 'cotondetulear': [], 'dachshund': [], 'dalmatian': [], 'dane': ['great'], 'deerhound': ['scottish'], 'dhole': [], 'dingo': [], 'doberman': [], 'elkhound': ['norwegian'], 'entlebucher': [], 'eskimo': [], 'finnish': ['lapphund'], 'frise': ['bichon'], 'germanshepherd': [], 'greyhound': ['italian'], 'groenendael': [], 'havanese': [], 'hound': ['afghan', 'basset', 'blood', 'english', 'ibizan', 'plott', 'walker'], 'husky': [], 'keeshond': [], 'kelpie': [], 'komondor': [], 'kuvasz': [], 'labradoodle': [], 'labrador': [], 'leonberg': [], 'lhasa': [], 'malamute': [], 'malinois': [], 'maltese': [], 'mastiff': ['bull', 'english', 'tibetan'], 'mexicanhairless': [], 'mix': [], 'mountain': ['bernese', 'swiss'], 'newfoundland': [], 'otterhound': [], 'ovcharka': ['caucasian'], 'papillon': [], 'pekinese': [], 'pembroke': [], 'pinscher': ['miniature'], 'pitbull': [], 'pointer': ['german', 'germanlonghair'], 'pomeranian': [], 'poodle': ['miniature', 'standard', 'toy'], 'pug': [], 'puggle': [], 'pyrenees': [], 'redbone': [], 'retriever': ['chesapeake', 'curly', 'flatcoated', 'golden'], 'ridgeback': ['rhodesian'], 'rottweiler': [], 'saluki': [], 'samoyed': [], 'schipperke': [], 'schnauzer': ['giant', 'miniature'], 'setter': ['english', 'gordon', 'irish'], 'sheepdog': ['english', 'shetland'], 'shiba': [], 'shihtzu': [], 'spaniel': ['blenheim', 'brittany', 'cocker', 'irish', 'japanese', 'sussex', 'welsh'], 'springer': ['english'], 'stbernard': [], 'terrier': ['american', 'australian', 'bedlington', 'border', 'cairn', 'dandie', 'fox', 'irish', 'kerryblue', 'lakeland', 'norfolk', 'norwich', 'patterdale', 'russell', 'scottish', 'sealyham', 'silky', 'tibetan', 'toy', 'welsh', 'westhighland', 'wheaten', 'yorkshire'], 'tervuren': [], 'vizsla': [], 'waterdog': ['spanish'], 'weimaraner': [], 'whippet': [], 'wolfhound': ['irish']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using API's that require authentication\n"
      ],
      "metadata": {
        "id": "hp1sFejexIpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to ensure we obtain an API key from the API provider to identify ourselves\n",
        "API_KEY='234567876543edcvbnmmngfert6789iuyfv'\n",
        "# Specify the user agent\n",
        "USER_AGENT='Muthee'\n",
        "# Specify the header using the headers parameters so as to identify ourselves\n",
        "headers={'user_agent':USER_AGENT}\n",
        "# Specify the key and other parameters that you require to specify\n",
        "params={\n",
        "    \"api_key\":API_KEY,\n",
        "    \"method\": \"chart.gettopartists\",\n",
        "    \"format\":\"json\"}\n",
        "# Import the requests library\n",
        "import requests\n",
        "response=requests.get(\"url\",headers=headers,parameters=params)\n"
      ],
      "metadata": {
        "id": "bFylu8zGxNjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pagination"
      ],
      "metadata": {
        "id": "eOvPC0FZ2mzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PAGINATION : Limiting the results fetched per page in an API(a page at a time)\n",
        "# Initializing an empty list to store up the results\n",
        "results=[]\n",
        "# First page\n",
        "page=1\n",
        "# last page\n",
        "total_pages=10,000\n",
        "page < total_pages\n",
        "\n",
        "while True:\n",
        "  response=requests.get('url',params={'page': page})\n",
        "  # Appending the responses in json format into the empty list\n",
        "  results.append(response.json())\n",
        "  # Increament page by 1\n",
        "  page+=1"
      ],
      "metadata": {
        "id": "YBmu4tjxUXCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rate Limiting.\n",
        "### This is using code to limit the number of times per second that we hit a particular API. This is done to prevent us from being banned from using the API"
      ],
      "metadata": {
        "id": "rVFd62Nb25wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the time.sleep() function that accepts a float to specify the number of seconds to await before proceeding to execute code\n",
        "import time\n",
        "print(\"one\")\n",
        "time.sleep(0.25)\n",
        "print(\"two\")"
      ],
      "metadata": {
        "id": "z0yR9D9T2ktZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another technique that we can use to use a local database to cache the results of any API call to avoid repetitive performance \n",
        "# ie. if we make the same call twice, the second time it'll check from the local cache.  We wi only have to wait if the result has not been previously cached\n",
        "! pip install requests-cache\n",
        "# Importing the library\n",
        "import requests-cache \n",
        "\n",
        "requests-cache.install_cache()"
      ],
      "metadata": {
        "id": "opHODLvc3qqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to make requests to API's\n",
        "def get_data(payload):\n",
        "  headers={'user_agent':USER_AGENT}\n",
        "  url='the underlying url'\n",
        "  params={\n",
        "    \"api_key\":API_KEY,\n",
        "    \"format\":\"json\"}\n",
        "  response=requests.get(url,headers=headers,params=payload) # Incase we need to add a payload as a dict as an arguments when calling  the function\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "9PdcJ1NPED-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using pagination and rate limiting in a function\n",
        "import time\n",
        "from IPython.core.display import clear_output\n",
        "# Creating a list to store my responses\n",
        "responses=[]\n",
        "\n",
        "# Begining page\n",
        "page=1\n",
        "\n",
        "# Last page\n",
        "total_page=99,999 # This is a dummy number to hard start\n",
        "\n",
        "# Creating a while loop to iterate until the current page is the total page\n",
        "\n",
        "while page<=total_pages:\n",
        "  # This is where pagination comes in where the limit per page is 500 and the page is set to the current page\n",
        "  payload={\n",
        "      'method':'url end point',\n",
        "      limit:500,\n",
        "      'page':page\n",
        "      }\n",
        "\n",
        "  # Print the output at that page to view progress\n",
        "  print(f\"Requesting page{page} out of {total_pages}\")\n",
        "\n",
        "  # Clear things at each point to make the output clearer\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  # Making the API call and store it in an object called response\n",
        "  response=get_data(payload)\n",
        "\n",
        "  # Print the message of the API fails to make a successful call and break the process\n",
        "  if response.status_code != 200:\n",
        "    print(response.text)\n",
        "    break\n",
        "\n",
        "  # Extract pagination information\n",
        "  page=int(response.json()['key1']['upto the key with the page number'])\n",
        "\n",
        "  total_pages=int(response.json()['key1']['key2']['upto the key with the page number'])\n",
        "\n",
        "  # Append the response to the empty list\n",
        "  responses.append(response)\n",
        "  # The logic behind the local cache checks whether a request has been previously cached if not,it caches the response and then waits and returns the response\n",
        "  # Checking whether the response is cached, if not cached, cache and sleep before proceeding\n",
        "  if not getattr(response,'from_cache',False)\n",
        "  time.sleep(0.25)\n",
        "  # Increament page number\n",
        "  page+=1\n",
        "  "
      ],
      "metadata": {
        "id": "0EM3k1yWFJ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The response is in list format. Using list comprehension to make a list of lists and combine them to form a dataframe\n",
        "import pandas as pd\n",
        "table=[pd.Dataframe(r.json['key_1']['the key that has the objects we want'] for r in responses)]\n",
        "# Concatenating the list of dataframes downwards\n",
        "tables_df=pd.concat(table)\n",
        "# We have a dataframe\n"
      ],
      "metadata": {
        "id": "cftAWa2bKqjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once we know specifically what we want we can concevert this into a python class with objects and attributes and produce a data frame\n"
      ],
      "metadata": {
        "id": "9BTWuwAFKZNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}